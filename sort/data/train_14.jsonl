{"text": "Wikipedia sobre f\u00edsica de part\u00edculas\nRapidinho. Me falaram que a defini\u00e7\u00e3o de f\u00edsica de part\u00edculas da Wikipedia era muito ruim. E de fato, era assim:\nParticle physics is a branch of physics that studies the elementary particle|elementary subatomic constituents of matter and radiation, and their interactions. The field is also called high energy physics, because many elementary particles do not occur under ambient conditions on Earth. They can only be created artificially during high energy collisions with other particles in particle accelerators.\nParticle physics has evolved out of its parent field of nuclear physics and is typically still taught in close association with it. Scientific research in this area has produced a long list of particles.\nMas hein? Part\u00edculas que s\u00f3 podem ser criadas em aceleradores? F\u00edsica de part\u00edculas \u00e9 ensinada junto com f\u00edsica nuclear? A pesquisa produz part\u00edculas (essa \u00e9 \u00f3tima!)?\nEm que mundo essa pessoa vive? Reescrevi:\nParticle Physics is a branch of physics that studies the existence and interactions of particles, which are the constituents of what is usually referred as matter or radiation. In our current understanding, particles are excitations of quantum fields and interact following their dynamics. Most of the interest in this area is in fundamental fields, those that cannot be described as a bound state of other fields. The set of fundamental fields and their dynamics are summarized in a model called the Standard Model and, therefore, Particle Physics is largely the study of the Standard Model particle content and its possible extensions.\nEu acho que ficou bem melhor. Vamos ver em quanto tempo algum editor esquentado da Wikipedia vai demorar para reverter. Atualmente est\u00e1 um saco participar da Wikipedia por causa dessas pessoas.", "id": "<urn:uuid:e7f0a003-07f1-4148-a77c-6e0cb215fc0e>", "dump": "CC-MAIN-2013-20", "url": "http://arsphysica.wordpress.com/2011/08/14/wikipedia-sobre-fisica-de-particulas/", "file_path": "s3://commoncrawl/crawl-data/CC-MAIN-2013-20/segments/1368696381249/warc/CC-MAIN-20130516092621-00000-ip-10-60-113-184.ec2.internal.warc.gz", "language": "en", "language_score": 0.6576704978942871, "token_count": 419, "score": 3.0, "int_score": 3}
{"text": "Refraction and Acceleration\nName: Christopher S.\nWhy is it that when light travels from a more dense to a\nless dense medium, its speed is higher? I've read answers to this\nquestion in your archives but, sadly, still don't get it. One answer\n(Jasjeet S Bagla) says that we must not ask the question because light is\nmassless, hence questions of acceleration don't make sense. It does,\nhowever, seem to be OK to talk about different speeds of light. If you\nstart at one speed and end at a higher one, why is one not allowed to\ntalk about acceleration? Bagla goes on to say that it depends on how the\nem fields behave in a given medium. It begs the question: what is it\nabout, say, Perspex and air that makes light accelerate, oops, travel at\ndifferent speeds? If you're dealing with the same ray of light, one is\nforced to speak of acceleration, no? What other explanation is there for\nfinal velocity>initial velocity? Arthur Smith mentioned a very small\n\"evanescent\" component that travels ahead at c. Where can I learn more\nabout this? Sorry for the long question. I understand that F=ma and if\nthere is no m, you cannot talk about a, but, again, you have one velocity\nhigher than another for the same thing. I need to know more than \"that's\njust the way em fields are!\"\nAn explanation that satisfies me relates to travel through an interactive\nmedium. When light interacts with an atom, the photon of light is absorbed\nand then emitted. For a moment, the energy of the light is within the atom.\nThis causes a slight delay. Light travels at the standard speed of light\nuntil interacting with another atom. It is absorbed and emitted, causing\nanother slight delay. The average effect is taking more time to travel a\nmeter through glass than through air. This works like a slower speed. An\nindividual photon does not actually slow down. It gets delayed repeatedly by\nthe atoms of the medium. A more dense medium has more atoms per meter to\nDr. Ken Mellendorf\nIllinois Central College\nCongratulations! on not being willing to accept \"that is just the way em\nfields are!\" The answer to your inquiry is not all that simple (my opinion),\nbut I won't try to do so in the limited space allowed here, not to say my\nown limitations of knowledge.\nLike so many \"simple\" physics questions, I find the most lucid, but\naccurate, explanation in\nRichard Feynman's, \"Lectures on Physics\" which most libraries will have.\nVolume I, Chapter 31-1 through 31-6, which describes refraction, dispersion,\ndiffraction. The \"answer\" has to do with how matter alters the electric\nfield of incident radiation, but I won't pretend to be able to do a better\njob than Feynman.\nThe answer is that you are not dealing with the same ray of light. In\nvacuum a photon just keeps going at the speed of light. In a medium,\nhowever, it interacts with the atoms, often being absorbed while bumping\nan atomic or molecular motion into a higher energy state. The excited\natom/molecule then can jump to a lower energy state, emitting a photon\nwhile doing so. This can obviously make light appear to travel slower in a\nIn detail, it is a very complicated question, requiring at least a\ngraduate course in electromagnetism to begin to understand. Why, for\nexample do the emitted photons tend to travel in the same direction?\nBest, Richard J. Plano\nClick here to return to the Physics Archives\nUpdate: June 2012", "id": "<urn:uuid:d2b35c16-35c7-477e-80c7-8dded3739ec4>", "dump": "CC-MAIN-2013-20", "url": "http://newton.dep.anl.gov/askasci/phy00/phy00434.htm", "file_path": "s3://commoncrawl/crawl-data/CC-MAIN-2013-20/segments/1368696381249/warc/CC-MAIN-20130516092621-00000-ip-10-60-113-184.ec2.internal.warc.gz", "language": "en", "language_score": 0.925911009311676, "token_count": 794, "score": 3.03125, "int_score": 3}
{"text": "Friday, 11 December 2009\nmental ray_Adding glow to the window glass\nThe above image was produced whilst at GMJ Design Ltd\nIn our latest book, we have covered a number of ways of emulating light without the need of creating a physical light.\nProduction companies often adopt similar methods to reduce the rendering times and retain the overall quality.\nIt is worth pointing out that the usage of Ambient Occlusion(i.e. AO) as a separate pass or/and directly from Max is utterly imperative for the final shot.\nThe following exercise will take you through another unique methodology of achieving similar results with reduced rendering times:\nAnother quick way of emulating \u201cglow\u201d/\"light\" on windows, is to in fact enable the glow function on the glass panes themselves.\nTo do this, simply go to the main material parameters, under the \"refraction\" group.\n1-Reduce the transparency to about 0.9 to prevent the surface from being fully transparent.\n2-To add a bit of blur to the transparency, decrease the glossiness to about 0.78. Note that, these values may vary depending on one\u2019s camera angle...and the level of transparency/blurriness intended.\n3-Next,change the colour swatch from white to a warm yellow.\nAlso, the \"fast (interpolate)\" function, can be enabled for quick and fast results, as the glossiness and its samples can often slow down the renders.However,it may create artifacts.\n4-Pan down to the \"self illumination (glow)\" parameters and enable the \"self illumination (glow)\" function.\n5-Under the \"luminance\" group, change it from \"unitless\" to \"physical units: cd/m2)\". Also, pick and choose any relevant bitmap (i.e. photo) that has a prominent light source.\nNote: The \"unitless\" function often creates artifacts on glossy reflections, therefore, to be avoided at all costs.\nDepending on time in hand, one can set the glow to generate light, or not, through the FG, by checking the \"illuminates the scene (when using fg)\" function.\n...and... \u201c...let there be light...\u201d!!!\nThe final rendered image below was achieved using this technique. I hope you like it.\nI hope you have found this post interesting.\nAlso check this new article in this Blog:\n3D Realism:Practical & Easy Workflows", "id": "<urn:uuid:7989e71c-c55d-4ab4-b972-24001740790f>", "dump": "CC-MAIN-2013-20", "url": "http://jamiecardoso-mentalray.blogspot.com/2009/12/mental-rayadding-glow-to-window-glass.html", "file_path": "s3://commoncrawl/crawl-data/CC-MAIN-2013-20/segments/1368696381249/warc/CC-MAIN-20130516092621-00000-ip-10-60-113-184.ec2.internal.warc.gz", "language": "en", "language_score": 0.8829333186149597, "token_count": 529, "score": 2.875, "int_score": 3}
{"text": "To make this sentence true i have to put <,>,or = in between ( ) the given fractions or Decimals? 7/20 ( ) 2/5 0.15 ( ) 1/8 Please explain?\nGiven a rectangular prism with dimensions w = 3, l = 4, and h = 6. If you created a second rectangular prism with the length doubled but the height halved (and the width stays the same), which would be the relation of the second volume to the first volume?\n740 mm Hg\nHow would you calculate the concentration of an aqueous solution of Ca(OH2)that has a pH of 12.57.\npoetry, part 1\nWhich one of the following lines best illustrates personification? A. A narrow wind complains all day. B. The fog comes on little cat feet. C. She floated graceful as a dove. D. Spring is a dream unsung.\nWilma's arm is broken when Paula knocks her down during an agrument. If Wilma sues Paula for battery, what damages is Wilma likely to receive?\nWell I saying both. I have describe two cultrals and their views on health. i shows african and caucaisians american. I know that african american An excessive impact on minority populations is chronic diseases. Chronic diseases that are consider in African American are AIDS, ...\nI need some help with what are some of the implications to health care providers in African American and Caucasian? Considering cultural views on the health as organic, health as harmony and disease as a curse or stigma\nI need some help with listing at two pros and cons for each of the given patient and caregiver roles as a -Mechanics and machines -Parents and children -Spiritualists and believers -Providers and consumers -Partners This is so I can right my paper\nFor Further Reading", "id": "<urn:uuid:656316dd-4afd-4827-9101-cca512394d6e>", "dump": "CC-MAIN-2013-20", "url": "http://www.jiskha.com/members/profile/posts.cgi?name=kia&page=6", "file_path": "s3://commoncrawl/crawl-data/CC-MAIN-2013-20/segments/1368696381249/warc/CC-MAIN-20130516092621-00000-ip-10-60-113-184.ec2.internal.warc.gz", "language": "en", "language_score": 0.9430113434791565, "token_count": 388, "score": 3.15625, "int_score": 3}
{"text": "US 5459828 A\nA method of producing a raster font from a contour font entailing the steps of deriving font metrics and character metrics of font characters in terms of arbitrary font units; scaling the font characters to a selected size and output resolution (pixels per unit length); altering the thickness of vertical and horizontal strokes of each character to a desired thickness, from the measured font metrics and character metrics, and including a difference applied to the thickness of the strokes by the printer process, to cause the strokes to be close to an integer number of pixels and thickness and to compensate for thinning and thickening which the printing engine might produce; bringing the leading and trailing edges of the characters to integer pixel locations, where such locations are based on and scaling the character between the leading and trailing edges proportionally therebetween, and producing a rasterized font from the altered contour font character.\n1. A printer processor implemented method for producing a raster font from a contour font defined by a list of points connected by curves, said raster font suitable for printing on a selected printer having known reproduction characteristics, including the steps of:\na) deriving for a contour font a set of font metrics and character metrics of a character in the font defined in terms of arbitrary font units;\nb) scaling a character contour defined in arbitrary font units to a selected size in units of pixels;\nc) altering thickness of character strokes by adjusting vertical and horizontal coordinates of each point defining the character contour in directions defined by a vector normal to the character contour at each point, by an amount required to obtain a desired thickness from the measured font metrics and character metrics, and an amount required to add to difference thickness thereto in accordance with the selected printer reproduction characteristics, said alteration amounts together causing the vertical and horizontal strokes to be sufficiently close to an integer number of pixels or half pixels so as to cause subsequent numerical rounding to produce uniform results across the font;\nd) grid aligning the contour of each character so that leading and trailing edges, and top and bottom edges of the contour of each character fall on whole or half pixel positions; and\ne) applying a rasterization function to the contour to convert each contour font character to a bitmap.\n2. The method as defined in claim 1 wherein in said grid alignment step, after aligning said leading and top edges of said contours of each character on a whole pixel position, the length of any lines joining leading and trailing edges, and lines joining top and bottom edges, are rounded to an integer number of whole or half pixels, and the trailing edge and bottom edges are aligned at whole pixel positions.\n3. In a printing system for printing on a selected printer having reproduction characteristics known and available as contour font correction data, wherein a font to be printed has a set of predefined font metrics and character metrics for each character in the font defined in terms of arbitrary font units, the method of preparing a contour font defined by a list of points connected by curves, for printing on the selected printer including the ordered steps of:\na) scaling each character in the contour font to a selected print resolution in pixels per unit length;\nb) altering thickness of character strokes by adjusting vertical and horizontal coordinates of each point defining the contour of each character to a desired thickness in directions defined by a vector, normal to the character contour at each point, by an amount required to obtain a desired thickness from the measured font metrics and character metrics, and an amount required to add a difference thickness thereto in accordance with the contour font correction data for a particular printer, to cause the vertical and horizontal stroke thickness to approximate an integer number of pixels so as to cause subsequent numerical rounding to produce uniform results across the font;\nc) grid aligning the contour of each character so that leading and trailing edges, and top and bottom edges of the contour of each character fall on whole pixel positions; and\nd) applying a rasterization function to the contour convert each contour font character to a bitmap.\n4. The method as defined in claim 3 wherein in said grid alignment step, after aligning said leading and top edges of said contours of each character on a whole pixel position, the length of any lines joining leading and trailing edges, and lines joining top and bottom edges, are rounded to an integer number of pixels or half pixels, and the trailing edge and bottom edges are aligned at whole pixel positions.\nA microfiche Appendix, having 5 fiche and 398 frames, is included herewith.\nThe present invention relates generally to the production of raster fonts from contour fonts, and more particularly, to a method of producing raster fonts from contour fonts taking into account characteristics of the contour font and the printer system which will ultimately print the font.\nA portion of the disclosure of this patent document contains material which is subject to copyright protection. The copyright owner has no objection to the facsimile reproduction by anyone of the patent document or the patent disclosure, as it appears in the Patent and Trademark Office files or records, but otherwise reserves all rights whatsoever.\nCross reference is made to U.S. patent application Ser. No. 07/416,211 by S. Marshall, entitled \"Rapid Halfbitting Stepper\", and assigned to the same assignee as the present invention.\nU.S. Pat. No. 4,675,830 to Hawkins is incorporated herein by reference for the purposes of background information on contour fonts. U.S. patent application Ser. No. 07/416,211 by S. Marshall, entitled \"Rapid Halfbitting Stepper\", and assigned to the same assignee as the present invention, is incorporated by reference herein for the purposes of teaching rasterization.\n\"Contour fonts\" is a term that refers to the use of outlines or contours to describe the shapes of characters used in electronic printing. In a contour font, each character shape is represented by one or more closed curves or paths that traces the boundary of the character. The contour is specified by a series of mathematical equations, which may be in any of several forms, the most common being circular arcs, straight lines, and polynomial expressions. The shape of the contour font is that of the ideal design of the character and, generally, does not depend on parameters associated with any printer. Contour fonts are ideal for use as master representations of typefaces.\nBitmap fonts or raster fonts are composed of the actual characters images that will be printed on a page, and are made by scaling contours to the appropriate size, quantizing or sampling them at the resolution of the printer, and filling the interiors of the characters with black bits or pixels. Achieving high quality in this process is difficult, except at very high resolutions, and requires knowledge of both the marking technology and typographic design considerations. Often, a bitmap font is delivered to a printer. There is a separate bitmap font for each size of a font, and sometimes separate fonts for landscape and portrait orientations.\nThe advantage of a contour font is that it can be scaled to any size and rotated to any angle by simple mathematics. Therefore, a single font suffices to represent all possible printing sizes and orientation, reducing font storage requirements, reducing the cost of font handling.\nThe difficulty in this approach is in achieving high quality character images during the sampling process which generates the raster characters from the contour masters. If the contour character is simply sampled, there will be random .+-.1 pixel variations in stroke thickness. If the printing process tends to erode black areas (common in write-white laser xerography) characters will be consistently too thin. If the printing process tends to fatten black areas (common in write black laser xerography), characters will be too thick.\nAt the high resolution employed in phototypesetters, usually greater than 1,000 spi, no special techniques are required for scaling and sampling the contour font to generate a raster font of any size. This is because although simple sampling necessarily has random one-bit errors, such errors are small compared to the size of the character, making errors insignificant. At 300, 400, and 600 spi though, character strokes are only three or four bits thick and each bit is important. The simplistic methods used by typesetter manufacturers are not sufficient.\nU.S. Pat. No. 4,675,830 to Hawkins, uses defined points in a contour font that must be grid aligned to pixel positions, but the stem widths or edges are not aligned.\nOf particular importance in generating fonts of optimal appearance are maintenance of uniform and correct stroke thickness among characters of a font and on different printing engines, uniform alignment of characters on a baseline, and uniform spacing of characters.\nIn accordance with the invention, there is provided a method for conversion of contour fonts to bitmap fonts with automatic thickening and thinning of strokes, and snapping of character edges to pixel or half pixel boundaries.\nIn accordance with the invention, there is provided a method of producing a raster font from a contour font entailing the steps of: first, deriving font metrics and character metrics of font characters in terms of arbitrary font units; scaling the font characters to a selected size and output resolution (pixels per unit length); altering the thickness of vertical and horizontal strokes of each character to a desired thickness, from the measured font metrics and character metrics, and including a difference applied to the thickness of the strokes by the printer process, to cause the strokes to be close to an integer number of pixels and thickness and to compensate for thing and thickening which the printing engine might produce; bringing the leading and trailing edges of the characters to integer pixel locations, where such locations are based on and scaling the character between the leading and trailing edges proportionally therebetween, and producing a rasterized font from the altered contour font character.\nThese and other aspects of the invention will become apparent from the following description used to illustrate a preferred embodiment of the invention in conjunction with the accompanying drawings in which:\nFIG. 1 shows a block diagram of the inventive optimized scaler rasterizer system.\nFIGS. 2A-2E illustrate the development of a raster font from a contour font, using the system described in FIG. 1.\nWith reference to the drawing, where the showing is for the purpose of illustrating an embodiment of the invention and not for the purpose of limiting same, the Figure shows a block diagram of the present invention which will be referred to and described hereinafter.\nFIG. 1 shows a block diagram of the contour rasterization process of the present invention. Beginning with a contour font 10, and with a character \"H\" shown in contour for illustration purposes at FIG. 2A the contour font is analyzed initially at hint generation step 20. At the hint generation, the parameters defining the font are determined, including measurement of the following metrics and character hints:\nTABLE 1______________________________________Font Metric Comments______________________________________Cap-height Height of the H, I or similar letterX-Height Height of the lower case xAscender Height of the lower case k, b, or similar letterDescender Position of the bottom of the lower case p or qThickness of Upper Vertical stroke thicknessCase Stems on upper case H or KThickness of Upper Horizontal Stroke onCase Cross-Strokes upper case E or FThickness of Lower Vertical stroke thicknessCase Stems on lower case k or lThickness of Lower Case Horizontal strokeCross-Strokes thickness on the fThickness of AuxiliaryCharacter StemsThickness of AuxiliaryCharacter Cross-StrokesHairline thickness Thickness of the cross bar on the e or the thin part of the o______________________________________\n(See, Appendix, page 13, ICFFontIODefs. Mesa)\nCharacter hints are generated for each character and include the following:\nTABLE 2______________________________________Character Metric Comments______________________________________Position of all horizontal Left sides of strokes areedges and indications of leading edges and rightwhether each edge is a sides or strokes areleading or trailing edge. trailing edges.Position of all verticaledges and indication ofwhether each edge is aleading or trailing edge.Direction of the normalvector (perpendicular)to the contour at eachcontrol point in thecontour, pointingtoward the whiteregion.______________________________________\nAt hint generation 20, the font metrics and character hints are computed. Since no special information on the actual character contours, beyond the contours themselves, is required to perform these computations, any font may be accepted as input. Height thickness metrics are obtained either by examining images of specific individual characters or by averaging amongst several characters. Optionally, if these values are supplied externally, that is, the provider of the font provides these values, the external values may be used instead of the computed values. Edge positions are determined by looking for long vertical or horizontal portions of contours. Normal vectors are perpendicular to the contour, and are computed from contour equations and by determining which side of the contour is black and which side is white. For those points required for curve reconstruction, but which are not on the curve, the normals are calculated as if a normal vector extended from the curve through those points.\nIn the attached Appendix, the source code, in the MESA language of the Xerox Corporation, is provided demonstrating one possible embodiment of the source code to accomplish the described goals. The Mesa programming language operates on a microprocessor referred to as the Mesa microprocessor, which has been well documented, for example, in Xerox Development Environment, Mesa Language Manual, Copyright 1985 Xerox Corporation, Part No. 610E00170. This particular software is derived from the Typefounders product of the Xerox Corporation, Stamford, Conn. The Typefounders product accomplished all these character and font metrics, but did not provide them externally. (See Appendix, pages 67-319,for relevant Typefounder software modules called by software implementing the current invention including: CharacterOpsDefs.mesa, CharacterOpslmplA.mesa, CharacterOpslmpIB.mesa, pages 67-105; ContourOpsDefs.mesa, ContourOpslmplA.mesa, ContourOpslmplB.mesa, ContourOpslmpIC.mesa, ContourOpslmplD.mesa, pages 106-195; FontOpsDefs.mesa, FontOpslmpl.mesa, pages 196-221; ImageOpsDefs.mesa, ImageOpslmplA.mesa, ImageOpslmplB.mesa, pages 222-265 TypefounderUtilsdefs.mesa, TypefounderlmplA.mesa, TypefounderlmpIB.mesa, pages 266-319) Additional software was added, which makes these values available for subsequent processing (See Appendix, page 1, TypeDefs.mesa for translation of the Typfounder data structure; page 36, MetricsDef.mesa, Metricslmpl.mesa, for measurement of font metrics; page 47, EdgeOpsDef. mesa, EdgeOpslmpl.mesa, for measurement of leading and trailing edge position) and performs the perpendiculars calculations (see, Appendix, page 56, NormalOpsdefs.mesa, NormalOpslmpl.mesa). This information is used for creation of a data structure for \"hints\" (see, Appendix, page 13, ICFFontlODefs. Mesa for creation of hint format for next steps). Of course, while in the Appendix, the various coded algorithms operating on the contour font data for the hint creation step 20 are given in the Mesa language, implementation is easily made in the Unix-based \"C\" language. The remainder of the system, and the algorithms incorporated will be described in the Appendix in the Unix-based \"C\" language.\nSelecting a contour font for use enables a program that looks for font data, and designates its final position in an output, while calling the various programs forming the steps that will be described further hereinbelow (see, Appendix, page 320, raster.c). The contour font rasterization program herein described is useful on a variety of hardware platforms, attributes of which can be selected for enhanced operation of the system, such as for example, a greater degree of precision in the calculations (the difference between 8 bit calculation and 32 bit calculation). (see, Appendix, page 340, std.h)\nAt transform step 30, (see, Appendix, page 343, xform.c) the contour font is converted from arbitrary contour font units, which are supplied by the provider of the font, to a particular size, expressed in units of pixels. Typically, contour font units are provided in terms of the contour itself, i.e., the height or size of the contour font is one (1). That is, lengths of characters are placed in terms of the size of the font character itself. These values must be transformed into pixel unit values, or whatever other value is required, e.g. the scaled font may be 30 pixels tall. Additionally, it is at this point that the contour font is rotated for either landscape or portrait mode printing, as required. Rotation and scaling is accomplished in accordance with a previously determined transformation matrix equation 35, which mathematically determines the conversion of the contour font from font measurements to pixel values at a selected orientation which can be used by the printer. The transformed character H is shown at FIG. 2B.\nSubsequent to transformation step 30, at thickening or thinning step 40, font characters are thickened or thinned based on requirements of the transformation, and requirements of the printing process. The character contour is adjusted to make the strokes thicker or thinner to compensate for the xerographic or other marking process to follow. There are three components of the thickening or thinning value. The first compensates for xerographic or other imaging effects. That is, if for example, the marking technology will thin strokes by half a pixel, then strokes are thickened by half a pixel in this step. The amount of thickening or thinning specified in the printer profile 50 separately for X and Y directions, and is created at the manufacturer of the printer, and inserted at the printer profile 50. (see, Appendix, page 348, thicken.c)\nThe second component of thickening, called residual thickening, is applied to insure uniformity of output strokes after the sampling or rasterization step. This amount for horizontal thickening on upper case letters, for example, is equal to the difference between the calculated ideal output vertical stem thickness, which is obtained by scaling the font metric to the proper size, and the result of rounding that thickness off to the actual pixel width which will be obtained after rasterization. This rounding is performed to the nearest whole pixel if half bitting is not enabled and to the nearest half pixel, if half bitting is enabled. There are separate values for horizontal or vertical directions and for upper case, lower case and auxiliary characters.\nThe third component of thickening and thinning applies only to very small characters, and prevents drop-outs of fine lines. This amount is equal to the difference between the calculated scaled thickness of the hairlines, after thickening by the font thickening steps, and the minimum stroke thickness specified in the printer profile. When applied, this thickening brings fine lines up to the value of the minimum stroke thickness. The value is zero if the hairline is already greater than the minimum stroke thickness. (This process, referred to as \"adaptive thickening,\" is not disclosed in the source code in the Appendix.)\nThe actual thickening or thinning applied is equal to the sum of these three components. Each component has an independent value in the X and Y directions. The direction to move each contour control point is specified by its normal vector. The thickened character H is shown at FIG. C.\nAt step 60, the snap function or grid alignment function is applied. The coordinate system of the character is varied in the horizontal direction to move vertical and horizontal edges to positions where pixel boundaries will be after rasterization, i.e., to a whole pixel position. This is to assure uniform stroke thickness in the rasterized character images. The process is to piecewise stretch or shrink the character to force edges to align the pixel boundaries. On the left hand sides of the characters, the left edge of each stroke is moved to the closest pixel boundary, while the right edge of the stroke is moved to the pixel boundary specified by rounding the stroke thickness. This process gives priority to maintaining uniform stroke thickness over absolute stroke position. That is to say, that after the left edge of the character has been moved to a whole pixel position, the thickness of the stroke, or portion of the character, is examined to determine its thickness. The thickness has already been adjusted in the thickness of thinning step, so that it is close to a whole pixel width. Accordingly, the right edge of the character is then moved to the nearest whole pixel, based on rounding the thickness of the pixel, as opposed to moving the right hand side to the nearest pixel. On the right hand sides of characters, the rolls of left and right edges of strokes are reversed. Right edges of strokes are anchored, while left edges are rounded relatively to corresponding right edges. (see, Appendix, page 355, snap.c).\nIn one variant of this scheme, the positions of left and right index points or width points, which are those points which determine character spacing and are made to coincide in constructing words, are snapped before the vertical edges.\nIn the vertical direction, snapping is performed to piecewise stretch characters so that positions of baseline, cap-height, x-height, and descender fall on pixel boundaries. Baseline and descender position are treated as bottoms of strokes, that is, anchored, while cap-height and x-height are treated as tops of strokes, computed relative to the baseline. All characters are snapped to all of these positions, ensuring uniform character alignment. After these font metric positions are snapped, horizontal edges are snapped in the same manner as vertical edges, with lower edges of strokes anchored and upper edges snapped relative to the lower edges in the lower half of the character and upper edges of strokes anchored and lower edges snapped relative to the upper edges in the upper half of the character.\nIn both horizontal and vertical directions, snapping is performed one edge at a time. That is, the first edge is snapped, stretching the coordinate system of the character slightly on one side of the snapped edge and shrinking it slightly on the other side. The second edge is then snapped, with its pre-snapping position perhaps already modified slightly by the first snap. This sequential snapping helps preserve local character features better than simultaneous snapping of all edges does. When the second edge is snapped, its area of influence on the coordinate grid extends only up to the first snapped edge, which stays in place. This process is then repeated for the remainder of the edges. The snapped character H is shown at FIG. 2D.\nOnce each character in the adjusted contour font has been placed in the grid and appropriately thickened and thinned, the final step is to sample the adjusted contour on discrete grid. This step 70 can optionally produce half bitted output images, as controlled by the printer profile. Light half bitting produces half bitting on curves and diagonals, while heavy half bitting will also produce half bitted vertical and horizontal edges.\nRasterization in a preferred embodiment of this invention is in accordance with the process described in U.S. patent application Ser. No. 07/416,211 by S. Marshall, entitled \"Rapid Halfbitting Stepper\", and assigned to the present assignee of the present invention. This application is incorporated by reference herein for the purposes of teaching rasterization. (see, Appendix, page 364, step.c and page 368, step.h for rasterization with halfbitting; page 372, bezline.c for stepping around curve; page 396, fill.c for filling). The rasterized character is shown at FIG. 2D.\nIt will not doubt be appreciated that numerous changes and modifications are likely to occur to those skilled in the art, and it is intended in the appended claims to cover all those changes and modifications which fall within the spirit and scope of the present invention.", "id": "<urn:uuid:5cf8f2cc-bc5c-42e1-a62b-bddf45ac1cba>", "dump": "CC-MAIN-2013-20", "url": "http://www.google.de/patents/US5459828", "file_path": "s3://commoncrawl/crawl-data/CC-MAIN-2013-20/segments/1368696381249/warc/CC-MAIN-20130516092621-00000-ip-10-60-113-184.ec2.internal.warc.gz", "language": "en", "language_score": 0.8994696736335754, "token_count": 5093, "score": 2.59375, "int_score": 3}
{"text": "The Gram-Schmidt Process\nNow that we have a real or complex inner product, we have notions of length and angle. This lets us define what it means for a collection of vectors to be \u201corthonormal\u201d: each pair of distinct vectors is perpendicular, and each vector has unit length. In formulas, we say that the collection is orthonormal if . These can be useful things to have, but how do we get our hands on them?\nIt turns out that if we have a linearly independent collection of vectors then we can come up with an orthonormal collection spanning the same subspace of . Even better, we can pick it so that the first vectors span the same subspace as . The method goes back to Laplace and Cauchy, but gets its name from J\u00f8rgen Gram and Erhard Schmidt.\nWe proceed by induction on the number of vectors in the collection. If , then we simply set\nThis \u201cnormalizes\u201d the vector to have unit length, but doesn\u2019t change its direction. It spans the same one-dimensional subspace, and since it\u2019s alone it forms an orthonormal collection.\nNow, lets assume the procedure works for collections of size and start out with a linearly independent collection of vectors. First, we can orthonormalize the first vectors using our inductive hypothesis. This gives a collection which spans the same subspace as (and so on down, as noted above). But isn\u2019t in the subspace spanned by the first vectors (or else the original collection wouldn\u2019t have been linearly independent). So it points at least somewhat in a new direction.\nTo find this new direction, we define\nThis vector will be orthogonal to all the vectors from to , since for any such we can check\nwhere we use the orthonormality of the collection to show that most of these inner products come out to be zero.\nSo we\u2019ve got a vector orthogonal to all the ones we collected so far, but it might not have unit length. So we normalize it:\nand we\u2019re done.", "id": "<urn:uuid:4a2ad899-7ba0-4bfc-9276-c5c5c0845fe6>", "dump": "CC-MAIN-2013-20", "url": "http://unapologetic.wordpress.com/2009/04/28/the-gram-schmidt-process/?like=1&source=post_flair&_wpnonce=fe7f791e1e", "file_path": "s3://commoncrawl/crawl-data/CC-MAIN-2013-20/segments/1368696381249/warc/CC-MAIN-20130516092621-00000-ip-10-60-113-184.ec2.internal.warc.gz", "language": "en", "language_score": 0.8971889019012451, "token_count": 447, "score": 3.625, "int_score": 4}
{"text": "Now that we\u2019ve said a lot about individual operators on vector spaces, I want to go back and consider some other sorts of structures we can put on the space itself. Foremost among these is the idea of a bilinear form. This is really nothing but a bilinear function to the base field: . Of course, this means that it\u2019s equivalent to a linear function from the tensor square: .\nInstead of writing this as a function, we will often use a slightly different notation. We write a bracket , or sometimes , if we need to specify which of multiple different inner products under consideration.\nAnother viewpoint comes from recognizing that we\u2019ve got a duality for vector spaces. This lets us rewrite our bilinear form as a linear transformation . We can view this as saying that once we pick one of the vectors , the bilinear form reduces to a linear functional , which is a vector in the dual space . Or we could focus on the other slot and define .\nWe know that the dual space of a finite-dimensional vector space has the same dimension as the space itself, which raises the possibility that or is an isomorphism from to . If either one is, then both are, and we say that the bilinear form is nondegenerate.\nWe can also note that there is a symmetry on the category of vector spaces. That is, we have a linear transformation defined by . This makes it natural to ask what effect this has on our form. Two obvious possibilities are that and that . In the first case we\u2019ll call the bilinear form \u201csymmetric\u201d, and in the second we\u2019ll call it \u201cantisymmetric\u201d. In terms of the maps and , we see that composing with the symmetry swaps the roles of these two functions. For symmetric bilinear forms, , while for antisymmetric bilinear forms we have .\nThis leads us to consider nondegenerate bilinear forms a little more. If is an isomorphism it has an inverse . Then we can form the composite . If is symmetric then this composition is the identity transformation on . On the other hand, if is antisymmetric then this composition is the negative of the identity transformation. Thus, the composite transformation measures how much the bilinear transformation diverges from symmetry. Accordingly, we call it the asymmetry of the form .\nFinally, if we\u2019re working over a finite-dimensional vector space we can pick a basis for , and get a matrix for . We define the matrix entry . Then if we have vectors and we can calculate\nIn terms of this basis and its dual basis , we find the image of the linear transformation . That is, the matrix also can be used to represent the partial maps and . If is symmetric, then the matrix is symmetric , while if it\u2019s antisymmetric then .", "id": "<urn:uuid:3bf09a24-c60d-45a0-b8e6-cc02ddac7ed6>", "dump": "CC-MAIN-2013-20", "url": "http://unapologetic.wordpress.com/2009/04/14/bilinear-forms/?like=1&source=post_flair&_wpnonce=8cb43e0c56", "file_path": "s3://commoncrawl/crawl-data/CC-MAIN-2013-20/segments/1368696381249/warc/CC-MAIN-20130516092621-00000-ip-10-60-113-184.ec2.internal.warc.gz", "language": "en", "language_score": 0.9191036224365234, "token_count": 608, "score": 2.546875, "int_score": 3}
{"text": "Let and be two differentiable functions. We will say that and are proportional if and only if there exists a constant C such that . Clearly any function is proportional to the zero-function. If the constant C is not important in nature and we are only interested into the proportionality of the two functions, then we would like to come up with an equivalent criteria. The following statements are equivalent:\nTherefore, we have the following:\nDefine the Wronskian of and to be , that is\nThe following formula is very useful (see reduction of order technique):\nRemark: Proportionality of two functions is equivalent to their linear dependence. Following the above discussion, we may use the Wronskian to determine the dependence or independence of two functions. In fact, the above discussion cannot be reproduced as is for more than two functions while the Wronskian does....", "id": "<urn:uuid:b7bc34b8-0f1f-4df8-8e8d-e56fc9c8fec5>", "dump": "CC-MAIN-2013-20", "url": "http://sosmath.com/diffeq/second/linearind/wronskian/wronskian.html", "file_path": "s3://commoncrawl/crawl-data/CC-MAIN-2013-20/segments/1368696381249/warc/CC-MAIN-20130516092621-00000-ip-10-60-113-184.ec2.internal.warc.gz", "language": "en", "language_score": 0.9316020011901855, "token_count": 180, "score": 2.6875, "int_score": 3}
{"text": "x2/3 + y2/3 = a2/3\nx = a cos3(t), y = a sin3(t)\nClick below to see one of the Associated curves.\n|Definitions of the Associated curves||Evolute|\n|Involute 1||Involute 2|\n|Inverse curve wrt origin||Inverse wrt another circle|\n|Pedal curve wrt origin||Pedal wrt another point|\n|Negative pedal curve wrt origin||Negative pedal wrt another point|\n|Caustic wrt horizontal rays||Caustic curve wrt another point|\nThe astroid only acquired its present name in 1836 in a book published in Vienna. It has been known by various names in the literature, even after 1836, including cubocycloid and paracycle.\nThe length of the astroid is 6a and its area is 3\u03c0a2/8.\nThe gradient of the tangent T from the point with parameter p is -tan(p). The equation of this tangent T is\nx sin(p) + y cos(p) = a sin(2p)/2\nLet T cut the x-axis and the y-axis at X and Y respectively. Then the length XY is a constant and is equal to a.\nIt can be formed by rolling a circle of radius a/4 on the inside of a circle of radius a.\nIt can also be formed as the envelope produced when a line segment is moved with each end on one of a pair of perpendicular axes. It is therefore a glissette.\nOther Web site:\n|Main index||Famous curves index|\n|Previous curve||Next curve|\n|History Topics Index||Birthplace Maps|\n|Mathematicians of the day||Anniversaries for the year|\n|Societies, honours, etc||Search Form|\nThe URL of this page is:", "id": "<urn:uuid:367a0525-d005-4467-93f1-a7ac123614d1>", "dump": "CC-MAIN-2013-20", "url": "http://www-history.mcs.st-andrews.ac.uk/history/Curves/Astroid.html", "file_path": "s3://commoncrawl/crawl-data/CC-MAIN-2013-20/segments/1368696381249/warc/CC-MAIN-20130516092621-00000-ip-10-60-113-184.ec2.internal.warc.gz", "language": "en", "language_score": 0.8595336079597473, "token_count": 409, "score": 2.71875, "int_score": 3}
{"text": "Major Section: BREAK-REWRITE\nExample: (brr@ :target) ; the term being rewritten (brr@ :unify-subst) ; the unifying substitutionwhere\nGeneral Form: (brr@ :symbol)\n:symbolis one of the following keywords. Those marked with\n*probably require an implementor's knowledge of the system to use effectively. They are supported but not well documented. More is said on this topic following the table.\n:symbol (brr@ :symbol) ------- ---------------------In general\n:target the term to be rewritten. This term is an instantiation of the left-hand side of the conclusion of the rewrite-rule being broken. This term is in translated form! Thus, if you are expecting (equal x nil) -- and your expectation is almost right -- you will see (equal x 'nil); similarly, instead of (cadr a) you will see (car (cdr a)). In translated forms, all constants are quoted (even nil, t, strings and numbers) and all macros are expanded.\n:unify-subst the substitution that, when applied to :target, produces the left-hand side of the rule being broken. This substitution is an alist pairing variable symbols to translated (!) terms.\n:wonp t or nil indicating whether the rune was successfully applied. (brr@ :wonp) returns nil if evaluated before :EVALing the rule.\n:rewritten-rhs the result of successfully applying the rule or else nil if (brr@ :wonp) is nil. The result of successfully applying the rule is always a translated (!) term and is never nil.\n:failure-reason some non-nil lisp object indicating why the rule was not applied or else nil. Before the rule is :EVALed, (brr@ :failure-reason) is nil. After :EVALing the rule, (brr@ :failure-reason) is nil if (brr@ :wonp) is t. Rather than document the various non-nil objects returned as the failure reason, we encourage you simply to evaluate (brr@ :failure-reason) in the contexts of interest. Alternatively, study the ACL2 function tilde-@- failure-reason-phrase.\n:lemma * the rewrite rule being broken. For example, (access rewrite-rule (brr@ :lemma) :lhs) will return the left-hand side of the conclusion of the rule.\n:type-alist * a display of the type-alist governing :target. Elements on the displayed list are of the form (term type), where term is a term and type describes information about term assumed to hold in the current context. The type-alist may be used to determine the current assumptions, e.g., whether A is a CONSP.\n:ancestors * a stack of frames indicating the backchain history of the current context. The theorem prover is in the process of trying to establish each hypothesis in this stack. Thus, the negation of each hypothesis can be assumed false. Each frame also records the rules on behalf of which this backchaining is being done and the weight (function symbol count) of the hypothesis. All three items are involved in the heuristic for preventing infinite backchaining. Exception: Some frames are ``binding hypotheses'' (equal var term) or (equiv var (double-rewrite term)) that bind variable var to the result of rewriting term.\n:gstack * the current goal stack. The gstack is maintained by rewrite and is the data structure printed as the current ``path.'' Thus, any information derivable from the :path brr command is derivable from gstack. For example, from gstack one might determine that the current term is the second hypothesis of a certain rewrite rule.\nbrr@-expressionsare used in break conditions, the expressions that determine whether interactive breaks occur when monitored runes are applied. See monitor. For example, you might want to break only those attempts in which one particular term is being rewritten or only those attempts in which the binding for the variable\nais known to be a\nconsp. Such conditions can be expressed using ACL2 system functions and the information provided by\nbrr@. Unfortunately, digging some of this information out of the internal data structures may be awkward or may, at least, require intimate knowledge of the system functions. But since conditional expressions may employ arbitrary functions and macros, we anticipate that a set of convenient primitives will gradually evolve within the ACL2 community. It is to encourage this evolution that\nbrr@provides access to the", "id": "<urn:uuid:460fe123-8906-4320-9cc8-f581b79ced1f>", "dump": "CC-MAIN-2013-20", "url": "http://planet.plt-scheme.org/package-source/cce/dracula.plt/4/0/docs/BRR_at_.html", "file_path": "s3://commoncrawl/crawl-data/CC-MAIN-2013-20/segments/1368696381249/warc/CC-MAIN-20130516092621-00000-ip-10-60-113-184.ec2.internal.warc.gz", "language": "en", "language_score": 0.8680592775344849, "token_count": 976, "score": 2.6875, "int_score": 3}
{"text": "Henry Robinson has created an excellent series of articles on consensus protocols. Henry starts with a very useful discussion of what all this talk about consensus really means: The consensus problem is the problem of getting a set of nodes in a distributed system to agree on something - it might be a value, a course of action or a decision. Achieving consensus allows a distributed system to act as a single entity, with every individual node aware of and in agreement with the actions of the whole of the network.\nIn this article Henry tackles Two-Phase Commit, the protocol most databases use to arrive at a consensus for database writes. The article is very well written with lots of pretty and informative pictures. He did a really good job.\nIn conclusion we learn 2PC is very efficient, a minimal number of messages are exchanged and latency is low. The problem is when a co-ordinator fails availability is dramatically reduced. This is why 2PC isn't generally used on highly distributed systems. To solve that problem we have to move on to different algorithms and that is the subject of other articles.\nReferences allow you to track sources for this article, as well as articles that were written in response to this article.", "id": "<urn:uuid:e37f32b6-0455-44bb-b719-a9e1ef06a7ff>", "dump": "CC-MAIN-2013-20", "url": "http://highscalability.com/blog/2009/2/9/paper-consensus-protocols-two-phase-commit.html", "file_path": "s3://commoncrawl/crawl-data/CC-MAIN-2013-20/segments/1368696381249/warc/CC-MAIN-20130516092621-00000-ip-10-60-113-184.ec2.internal.warc.gz", "language": "en", "language_score": 0.9730798602104187, "token_count": 242, "score": 2.828125, "int_score": 3}
{"text": "In this section we will describe some basis of hardware involved in Nano.\n Block Diagram\n Power Supply\nJz4720 support 3 different boot sources. The boot sequence is controlled by boot_sel pin values [1:0]. The configuration of BOOT_SEL1 and BOOT_SEL1 [1:0] is showed as below:\n|0||0||Boot from external ROM at CS4|\n|0||1||Boot from USB device|\n|1||0||Boot from 512 page size NAND flash at CS1|\n|1||1||Boot from 2048 page size NAND flash at CS1|\n Arquitectura General\nIt is necessary, for the operation of the Nanonote Board to store many sections of executable programs in volatile and non-volatile memories. The volatile memories are used like Random Access Memories (RAM) due to its low access time and unlimited number of Read/Write cycles. On the other hand, the Non-volatile memories (NAND, SD) stores for long periods of time the required information to operate the Embedded System.\nUniversal Serial Bus (USB) is a way of setting up communication between a computer and peripheral devices. USB is intended to replace many varieties of serial and parallel ports. USB can connect computer peripherals such as mice, keyboards, PDAs, gamepads and joysticks, scanners, digital cameras, printers, personal media players, flash drives, and external hard drives. For many of those devices, USB has become the standard connection method.\nA USB system has an asymmetric design, consisting of a host, a multitude of downstream USB ports, and multiple peripheral devices connected in a tiered-star topology. Additional USB hubs may be included in the tiers, allowing branching into a tree structure with up to five tier levels. A USB host may have multiple host controllers and each host controller may provide one or more USB ports. Up to 127 devices, including the hub devices, may be connected to a single host controller.\n Serial and JTAG\nThe NAND in the Ben NanoNote:\n- Has pages that are 4096 bytes in length\n- Has blocks that are 128 pages in length\n- Has 4096 blocks of storage in total\n- 4096 \u00d7 128 \u00d7 4096 = 2147483648 bytes ( 2 GB)\nroot@ben:/# cat /proc/mtd dev: size erasesize name mtd0: 00400000 00080000 \"NAND BOOT partition\" mtd1: 00400000 00080000 \"NAND KERNEL partition\" mtd2: 7f800000 00080000 \"NAND ROOTFS partition\"\n- size is the capacity of the partition in bytes. 7f800000 is just shy of 2 GB\n- erasesize is the block size. 00080000 is 512 KB ( 128 \u00d7 4096 byte pages)\n Samsung K9GAG08X0M NAND flash chip, hardware info\n1 Page = (4K + 128)Bytes 1 Block = 128 Pages (512K + 16K) Bytes 1 Devie = (512K + 16K) Bytes x 4,096 Blocks 1 Device = (4K+128)B x 128Pages x 4,096 Blocks = 16,896 Mbits\n- NanoNote partitions\n|Name||Size||Block offset||Page offset|\n- NanoNote partitions AFTER OpenWrt_Software_Image#Image_2010-11-17, we change the rootfs to 512M\n|Name||Size||Block offset||Page offset|\nPCB 08.50 (ben)\n Micro-SD pins on testpads\nPin TP note ------------------ #1 TP14 data2 #2 TP15 cd/data3 / _CS #3 TP17 cmd / mosi #4 sdVCC switched by Q4 (fet?) controlled via line from cpu (on TP11) #5 TP16 clock #6 GND #7 TP12 data0 / miso #8 TP13 data1\n Serial pins\n System information\n GPIO pins\nThe Jz4720 has only a limited number of pins as outputs to the board. Furthermore, several functions take up gpio pins which are therefore not usable for other functions. Those devices are the sdram and nand controller, lcd controller and mmc+sd controller. Below is a table showing how they are used. Please complete this table. The missing entries are not connected to a pad in the Jz4720.\n Port A\n- 01 sdram data 0\n- 03 sdram data 1\n- 05 sdram data 2\n- 07 sdram data 3\n- 08 sdram data 4\n- 09 sdram data 5\n- 10 sdram data 6\n- 11 sdram data 7\n- 12 sdram data 8\n- 13 sdram data 9\n- 15 sdram data 10\n- 17 sdram data 11\n- 22 sdram data 12\n- 26 sdram data 13\n- 28 sdram data 14\n- 30 sdram data 15\n Port B\n- 00 sdram address 0\n- 01 sdram address 1\n- 02 sdram address 2\n- 03 sdram address 3\n- 04 sdram address 4\n- 05 sdram address 5\n- 06 sdram address 6\n- 07 sdram address 7\n- 08 sdram address 8\n- 09 sdram address 9\n- 10 sdram address 10\n- 11 sdram address 11\n- 12 sdram address 12\n- 13 sdram address 13\n- 14 sdram address 14\n- 15 nand command latch\n- 16 nand address latch\n- 17 SHDN_HOST???\n- 18 TP23 (free)\n- 19 sdram dcs\n- 20 sdram ras\n- 21 sdram cas\n- 22 ???\n- 23 sdram cke\n- 24 sdram cko\n- 25 sdram cs1\n- 26 sdram cs2\n- 27 USB ID\n- 28 ???\n- 29 Audio output enable\n- 30 TP25 (free)\n- 31 ???\n Port C\n- 00 lcd data 0\n- 01 lcd data 1\n- 02 lcd data 2\n- 03 lcd data 3\n- 04 lcd data 4\n- 05 lcd data 5\n- 06 lcd data 6\n- 07 lcd data 7\n- 08 TP 35 (unused)\n- 09 TP 36 (unused)\n- 10 keyboard out 0\n- 11 keyboard out 1\n- 12 keyboard out 2\n- 13 keyboard out 3\n- 14 keyboard out 4\n- 15 keyboard out 5\n- 16 keyboard out 6\n- 17 keyboard out 7\n- 18 lcd pixel clock\n- 19 lcd hsync\n- 20 lcd vsync\n- 21 LCD SPI chipselect\n- 22 LCD SPI data\n- 23 LCD SPI clock\n- 24 sdram write enable 1\n- 27 Charge detect\n- 28 nand read enable\n- 29 nand write enable\n- 30 nand flash ready/busy\n- 31 select uart or jtag on pad 147; not a gpio pin\n Port D\n- 00 SD Card detect\n- 02 SD Card power enable\n- 04 Speaker AMP enable\n- 06 Shutdown detect\n- 08 SD Card command\n- 09 SD Card clock\n- 10 SD Card data 1\n- 11 SD Card data 2\n- 12 SD Card data 3\n- 13 SD Card data 4\n- 15 TP 38 (free)\n- 18 Keyboard in 1\n- 19 Keyboard in 2\n- 20 Keyboard in 3\n- 21 Keyboard in 4\n- 22 Keyboard in 5\n- 23 Keyboard in 6 (i2c?)\n- 24 Keyboard in 7 (i2c?)\n- 25 uart transmit\n- 26 Keyboard in 8 (uart receive)\n- 27 Buzzer, controlled with pwm4. Piezo-electric buzzer; not related to soundcard output.\n- 28 USB detect\n- 29 power button\n Test Points Under Battery\nThis page is to describe all test pins under battery label. You may want to probe or discover them as long as you tear off battery label. Also this whole page you can reference to the schematic of AVT2 RC1 Reference Board.\n- TP 9, V33, system voltage 3.3V when power on\n- TP 12, SDD0, MSC_D0/GPD10(in/out) of jz4720, MSC data bit 0, Please see MicroSD.\n- TP 13, SDD1, MSC_D1/GPD11(in/out) of jz4720, MSC data bit 1, Please see MicroSD.\n- TP 14, SDD2, MSC_D2/GPD12(in/out) of jz4720, MSC data bit 2, Please see MicroSD.\n- TP 15, SDD3, MSC_D3/GPD13(in/out) of jz4720, MSC data bit 3, Please see MicroSD.\n- TP 16, SDCLK, MSC_CLK/GPD9(out) of jz4720, MSC clock output, Please see MicroSD.\n- TP 17, SDCMD, MSC_CMD/GPD8(in/out) of jz4720, MSC command, Please see MicroSD.\n- TP 19, CS1_N, CS1_/GPB25(out) of jz4720, This connects to NAND (NAND chip enable).\n- TP 20, CS2_N, CS2_/GPB26(out) of jz4720, This connects to NAND (NAND chip enable 2).\n- TP 24, POP, GPB29(out) of jz4720, This pin is the purpose on eliminate POP sound free. Please also see Audio IN OUT.\n- TP 25 COB TEST, GPB30 of jz4720, Purpose during production test.\n- TP 26, FWE_N, FWE_/GPC29(out) of jz4720, This connects to NAND WE_(NAND flash write enable). Please see NAND.\n- TP 29, FRB_N, FRB_/GPC30(in) of jz4720, This connects to NAND FRB(NAND flash ready/busy). Please see NAND.\n- TP 32, CHARGE_N, GPC27(in) of jz4720, Through this input pin that shows if charging or not. Please see Power Supply Circuit & Battery Charger.\n- TP 39, LCD0, pin 16 of CON2 FPC connector, GPC0(out) of jz4720, Please see LCD.\n- TP 40, LCD1, pin 15 of CON2 FPC connector, GPC1(out) of jz4720, Please see LCD.\n- TP 41, LCD2, pin 14 of CON2 FPC connector, GPC2(out) of jz4720, Please see LCD.\n- TP 42, LCD3, pin 13 of CON2 FPC connector, GPC3(out) of jz4720, Please see LCD.\n- TP 43, LCD4, pin 12 of CON2 FPC connector, GPC4(out) of jz4720, Please see LCD.\n- TP 44, LCD5, pin 11 of CON2 FPC connector, GPC5(out) of jz4720, Please see LCD.\n- TP 45, LCD6, pin 10 of CON2 FPC connector, GPC6(out) of jz4720, Please see LCD.\n- TP 46, LCD7, pin 9 of CON2 FPC connector, GPC7(out) of jz4720, Please see LCD.\n- TP 47, LCDDCLK, pin 17 of CON2 FPC connector, GPC18(out) of jz4720, Please see LCD.\n- TP 48, VSYNC, pin 18 of CON2 FPC connector, GPC20(out) of jz4720, Please see LCD.\n- TP 49, HSYNC, pin 19 of CON2 FPC connector, GPC19(out) of jz4720, Please see LCD.\n- TP 50, LCDCS, pin 20 of CON2 FPC connector, GPC21(out) of jz4720, Please see LCD.\n- TP 51, LCDSCL, pin 21 of CON2 FPC connector, GPC22(out) of jz4720, Please see LCD.\n- TP 52, LCDSDA, pin 22 of CON2 FPC connector, GPC23(in/out) of jz4720, Please see LCD.\n- TP 60, KEYOUT2, GPC11(out) of jz4720, Please see Keyboard.\n- TP 62, KEYOUT4, GPC13(out) of jz4720, Please see Keyboard.\n- TP 63, KEYOUT5, GPC14(out) of jz4720, Please see Keyboard.\n- TP 64, KEYOUT6, GPC15(out) of jz4720, Please see Keyboard.\n- TP 66, KEYOUT8, GPC17(out) of jz4720, Please see Keyboard.\n- TP 67, KEYIN1, GPD18(in) of jz4720, Please see Keyboard.\n- TP 74, KEYIN8, GPD26(in) of jz4720, Serial console RXD pin in, Please see Serial console.\n- TP 75, TXD, GPD25(out) of jz4720, Serial console TXD pin out, Please see Serial console.\n- TP 76, GND, System ground, Please see Serial console.\n- TP 79, USBDET, GPD28(input) of jz4720, Jz4720 can detect a \"LOW\" status during usb host cable is plug in.", "id": "<urn:uuid:45c61dcf-839e-455f-8328-f268b0b88767>", "dump": "CC-MAIN-2013-20", "url": "http://en.qi-hardware.com/wiki/Hardware_basics", "file_path": "s3://commoncrawl/crawl-data/CC-MAIN-2013-20/segments/1368696381249/warc/CC-MAIN-20130516092621-00000-ip-10-60-113-184.ec2.internal.warc.gz", "language": "en", "language_score": 0.7262580990791321, "token_count": 2985, "score": 2.78125, "int_score": 3}
{"text": "ANM uses specific ports for its processes. Figure A-1 illustrates a typical ANM server deployment in a network. This illustration identifies the protocols and ports used by the different network devices in a typical deployment.\n\u2022Table A-1 lists the ports used for ANM client (browser) or ANM server and ANM high availability communication.\n\u2022Table A-2 lists the ports used for communication between ANM and managed devices.\nFigure A-1 ANM Server Deployment\nTable A-1 Ports Used by ANM in a Network Deployment1\nDefault port if ANM is configured for access using HTTP (using anm-installer).\nDefault port if ANM is configured for access using HTTPS (using default install option).\nMySQL Database system (ANM HA installation opens this port to communicate with the peer ANM).\nTCP (10444) and TCP (10445)\nANM License Manager (ANM HA installation opens these two ports to communicate with the peer ANM).\nPort used by ANM server to communicate to Email Gateway through SMTP.\nPort used by ANM server to send out trap notification to external NMS application.\n1It is highly recommended that you run ANM on a stand-alone device. However, if you run ANM on a shared device, please note that ANM locally opens the following ports for internal communication:", "id": "<urn:uuid:5aaa1e56-80e5-4313-ad72-1ec87e308193>", "dump": "CC-MAIN-2013-20", "url": "http://www.cisco.com/en/US/docs/net_mgmt/application_networking_manager/2.0/user/guide/UG_ports.html", "file_path": "s3://commoncrawl/crawl-data/CC-MAIN-2013-20/segments/1368696381249/warc/CC-MAIN-20130516092621-00000-ip-10-60-113-184.ec2.internal.warc.gz", "language": "en", "language_score": 0.8468099236488342, "token_count": 287, "score": 2.65625, "int_score": 3}
{"text": "LANs to WANs(c) The Complete Management Guide\nAuthors: Muller N.J.\nPublished year: 2003\n|< Day Day Up >|\nDepending on the situation facing network managers, bridges can be used to either extend or segment LANs. At one level, bridges can be used for segmenting LANs into smaller subnets to improve performance, control access, and facilitate fault isolation and testing without impacting the overall user population. At another level, they are used to create an extended network that greatly expands the number of devices that can be supported and the services available to each user . Bridges may even offer additional features such as data compression, which has the effect of providing greater throughput over low-speed lines. Compression ratios of 2:1 all the way down to 6:1 may be selected by the network manager, depending on what the vendor offers with a specific product.\nAs noted, bridging occurs at the data link layer (see Figure 5.1), which provides physical addressing, manages access to the physical medium, controls data flow, and handles transmission errors. Bridges analyze incoming frames, make forwarding decisions based on the source and destination addresses of those frames, and then forward the frames to their destinations. Sometimes, as in source-route bridging, the frame contains the entire path to the destination. In other cases, as in transparent bridging, frames are forwarded one hop at a time toward the destination.\nFigure 5.1: Bridge functionality in reference to the OSI model.\nBridges can be either local or remote. Local bridges provide direct connections between many LAN segments in the same area. Remote bridges connect LAN segments in different areas, usually over telecommunication lines. There are several kinds of bridging and all may be supported in the same device:\nTransparent bridging \u2014used mostly in Ethernet environments that have the same media types, these bridges keep a table of destination addresses and outbound interfaces.\nSource-route bridging \u2014used mostly in token-ring environments, these bridges only forward frames based on the routing indicator contained in the frame. End stations are responsible for determining and maintaining the table of destination addresses and routing indicators.\nTranslation bridging \u2014used to bridge data between different media types, these devices typically go between Ethernet and FDDI or token ring to Ethernet.\nSource-route translation bridging \u2014this is a combination of source-route bridging and transparent bridging that allows communication in mixed Ethernet and token-ring environments. (Translation bridging without routing indicators between token ring and Ethernet is also called source-route transparent bridging.)\nThe engine for transparent bridging is the spanning tree algorithm (STA), which dynamically discovers a loop-free subset of the network\u2019s topology. The STA accomplishes this by placing active bridge ports that create loops into a standby or blocked condition. A blocked port can provide redundancy in that if the primary port fails, it can be activated to take the traffic load.\nThe spanning tree calculation is triggered when the bridge is powered up and whenever a change in topology is detected . A topology change might occur when a forwarding port is going down (blocking) or when a port transitions to forwarding and the bridge has a designated port, which also indicates that the bridge is not standalone. Configuration messages known as bridge protocol data units (BPDUs) actually trigger the spanning tree calculation. These messages are exchanged between bridges at regular intervals set by the network manager, usually 1 to 4 seconds.\nOnce a change in topology is detected, this information must be shared with all bridges on the network. This is a two-step process that starts when a bridge notifies the root bridge of the spanning tree by sending it a special BPDU known as a topology change notification (TCN). The bridge sends the TCN out over its root port. The root bridge acknowledges the message by sending back a normal configuration BPDU with the topology change acknowledgment (TCA) bit set. The second step in the topology update process entails the root bridge sending out configuration BPDUs with the topology change (TC) bit set. These BPDUs are relayed by every bridge, so they can become aware of the changed topology.\nThere are some problems associated with spanning tree. The more hosts on the network, the higher the probability of topology changes. For example, a directly attached host, such as a client or server, will trigger a topology change when powered off, then go on to clear an operating system problem. In a large, flat network, the point can be reached when it is continually in topology change status. The resulting high level of flooding can lead to an unstable STP environment. To deal with this problem, vendors have come up with ways to avoid TCN generation for certain events. For example, the network manager can configure the bridge so that it issues a TCN when a server is power cycled, but not when client devices are power cycled. If a bridge port going up or down is not deemed an important event, this event too can be programmed not to issue a TCN.\nSource-route bridging (SRB) is used in the token-ring environment as the method by which a station establishes a route through a multiple-ring network to its destination. The first step for a station to reach another is to create a packet called an explorer. This packet is copied by all bridges in the network, with each of them adding information about itself before passing it on. The explorer packet\u2019s routing information field (RIF) contains the information of where it has traversed through the network and within the RIF; a route descriptor stores the path it has taken through the network.\nAs the explorer packet is constructed on its way through the network, the destination station will start receiving data packets from the originating station. Based on the contents of the explorer packet, the destination station will then decide which route to use to send data packets back to the originating station. Or it will send its own explorer packet so that the originating station can determine its own route.\nThe explorer packet is limited in terms of how many rings it can hold in the routing information field. Although the RIF can hold a total of 14 rings, IBM long ago limited this to seven. Other vendors also adopted this limitation. Consequently, an explorer packet that has traversed seven rings will be dropped in the network. To control traffic in the network with more precision, parameters can be set in the bridge to decrease this number even further, so that packets that reach X number of rings (any number below seven) will be dropped.\nWhile explorers are limited to traversing only seven rings, in a meshed ring environment, one explorer can finish being copied by many bridges, which can cause too many explorers. Explorer storms can be prevented in redundant network topologies by setting the bridge to filter out explorers that have already been forwarded once. Since explorer traffic can be distinguished from regular source route traffic, the network manager can issue commands that check the bridge for various parameters, such as the number of explorers that were dropped outbound on that interface.\nWhile Ethernet has become the network of choice for new installations, there is still a good amount of token ring in use, making it necessary to mix the two environments for data exchange. Doing so is complicated because some very fundamental differences between Ethernet and token ring must be reconciled. Token ring has functional addresses, while Ethernet primarily relies on broadcasts.\nFurthermore, MAC addresses on the Ethernet are different from MAC addresses on the token ring. Ethernet does not have a source-route bridging capability and token ring has a routing information field. Finally, token ring and Ethernet use different methods to read the bits into their adapters.\nTo unify the two environments, vendors have come up with various methods such as translation bridging. This is a type of bridging that is implemented on networks that use different MAC sublayer protocols, providing a method of resolving differences in header formats and protocol specifications. Since there are no real standards in how communication between two media types should occur, however, no single translation implementation can be called correct. The only consideration for network managers is to select a method of translation and implement it uniformly throughout the network.\nEssentially, the bridges reorder source and destination address bits when translating between Ethernet and token-ring frame formats. The problem of embedded MAC-addresses can be resolved by programming the bridge to look for various types of MAC addresses. Some translation-bridges simply check for the most popular embedded addresses. If others are used, the bridge must be programmed to look for them as well. But if translation-bridging software runs in a multi-protocol router, which is very common today, these protocols can be routed and the problem avoided entirely.\nToken ring\u2019s RIF field has a component that indicates the largest frame size that can be accepted by a particular source-route bridging implementation. Translation bridges that send frames from the transparent-bridging domain to the SRB domain usually set the maximum transfer unit (MTU) field to 1,500 bytes to limit the size of token-ring frames entering the transparent-bridging domain, because this is the maximum size of Ethernet frames. Some hosts cannot process this field correctly, in which case translation bridges are forced to drop the frames that exceed Ethernet\u2019s MTU size.\nBits representing token-ring functions that are absent in Ethernet are discarded by translation bridges. For example, token ring\u2019s priority, reservation, and monitor bits are discarded during translation. And token ring\u2019s frame status bits are treated differently, depending on the bridge manufacturer; the products of some manufacturers may even ignore these bits.\nSometimes, the bridge will have the C bit set, indicating that the frame has been copied, but not the A bit set, indicating that the destination station recognizes the address. In the former case, a token-ring source node determines if the frame it sent has become lost. Advocates of this approach claim that reliability mechanisms, such as the tracking of lost frames, are better left for implementation in Layer 4 of the OSI model. Advocates of setting the C bit argue that this bit must be set to track lost frames, but that the A bit cannot be set because the bridge is not the final destination.\nTranslation bridges also can be used to create a software gateway between the token ring and Ethernet domains. To the SRB end stations, the translation bridge has a ring number and a bridge number associated with it, so it looks like a standard source-route bridge. In this case, the ring number reflects the entire transparent-bridging domain. To the transparent-bridging domain, the translation bridge is just another transparent bridge.\nWhen bridging from the SRB domain to the transparent-bridging domain, SRB information is removed. Token ring\u2019s routing information fields usually are cached for use by any subsequent return traffic. When bridging from the transparent bridging to the SRB domain, the translation bridge checks the frame to see if it has a multicast or unicast destination. If the frame has a multicast or broadcast destination, it is sent into the SRB domain as a spanning-tree explorer. If the frame has a unicast address, the translation bridge looks up the destination in the RIF cache. If a path is found, it is used and the RIF information is added to the frame; otherwise , the frame is sent as a spanning-tree explorer.\nAnother solution to unify the Ethernet and token-ring environments is source-route translation bridging (SRTLB). This entails the addition of bridge groups to the interfaces of both the token ring and Ethernet bridges to create a transparent bridge domain between the two environments. The bridges at each end are responsible for establishing the path through the network. When a bridge on a token ring receives a packet from an Ethernet, for example, path establishment is handled as follows (see Figure 5.2):\nFigure 5.2: Source-route translation bridging, from token ring to Ethernet.\nBridge-1 receives a packet from the Ethernet. This is from PC-1 to the host.\nBridge-1 needs a RIF to reach the host, so it creates an explorer to learn the path to reach the host.\nAfter Bridge-1 receives the response, it sends the response (without a RIF) to the Ethernet station.\nPC-1 sends an exchange identifier (XID) to the host MAC address.\nBridge-1 gets the Ethernet packet, attaches the RIF to the host, and sends the packet on its way.\nAs far as the host is concerned , the Ethernet is sitting on a pseudo ring. This is configured with the source-bridge transparent command on the bridge. The pseudo ring makes the host treat the Ethernet as if it were a token ring.\n|< Day Day Up >|\nLANs to WANs(c) The Complete Management Guide\nAuthors: Muller N.J.\nPublished year: 2003", "id": "<urn:uuid:e16b4240-d208-4ee2-8272-ce223fa2146e>", "dump": "CC-MAIN-2013-20", "url": "http://flylib.com/books/en/4.62.1.44/1/", "file_path": "s3://commoncrawl/crawl-data/CC-MAIN-2013-20/segments/1368696381249/warc/CC-MAIN-20130516092621-00000-ip-10-60-113-184.ec2.internal.warc.gz", "language": "en", "language_score": 0.922479510307312, "token_count": 2669, "score": 3.359375, "int_score": 3}
{"text": "An Introduction To 127.0.0.1\n127.0.0.1 is an IP address utilized for a looplock network connection. What does this mean? If\na user tries to connect to this IP address, they will be sent back to their computer. The address\nis also known as a localhost. The localhost is the computer.\nHow the Localhost Works\nIf the command is relayed to the localhost, you would be hooked up to the system where the\ncommands were sent out. For instance, suppose the computer is called \"Joker\". If you telnet\nfrom the Joker computer to the localhost, a message will appear. It will attempt to hook up to\nThe localhost is employed in lieu of the computer hostname to be linked to. This IP address is\nthe most wisely used localhost address. However, you can actually use any IP address\nprovided it starts with 127. This means 127.*.*.* can be used as a localhost.\nEstablishing a connection with the loopback address is similar to creating a connection with\nremote network computers. The only difference is you don't have to deal with network\nFor this reason it is widely utilized by software developers. It is also used by system\nadministrators. It is often used for testing programs and apps. If the connection is IPv4, the\ncomputer's loopback address will be the 127.*.*.*. The subnet mask is typically 255.0.0.0.\nThis IP addresses 127.*.*.*. are defined in RFC 330 as Special-Use IPv4 Addresses. The\n127.0.0.0/8 block is defined as the Net host loopback address. If a higher level protocol sends\na datagram anywhere in the block, it will be looped in the host. This is typically implemented\nwith the 127.0.0.1 / 32 for looplock. However, addresses in the block must not be visible\nanywhere else in the network.\nThere is also a localhost IPv6 version. In RFC 3513, it is defined as Internet Protocol Version\n6 (IPv6) Addressing Architecture::1/128.\nMore Information about the Localhost\nIn simple terms, the localhost means the computer. It is the hostname allocated loopback\nnetwork interface address. The name is likewise a domain name. This will help prevent\nconfusion with the hostname definition. In IPv6, the loopback IP address is ::1. The localhost\nis stated when one would usually use the computer hostname. For instance, a browser using\nan HTTP server to http://localhost will show the local website home page. This will be\npossible if the server is set up properly to work the loopback interface.\nThe loopback address can also be used for linking up to a game server. It can also be used for\nthe various inter-process communications. This facts about 127.0.0.1 indicate how\nfundamental and basic the localhost is to a system. That's why it is so crucial for network", "id": "<urn:uuid:0cfb12fb-ebfd-4e6a-8720-c551d7e97801>", "dump": "CC-MAIN-2013-20", "url": "http://pdfcast.org/pdf/a-guide-to-localhost", "file_path": "s3://commoncrawl/crawl-data/CC-MAIN-2013-20/segments/1368696381249/warc/CC-MAIN-20130516092621-00000-ip-10-60-113-184.ec2.internal.warc.gz", "language": "en", "language_score": 0.893843948841095, "token_count": 644, "score": 3.8125, "int_score": 4}
